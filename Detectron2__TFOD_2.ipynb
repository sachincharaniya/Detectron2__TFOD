{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. How do you install Detectron2 using pip and check the version of Detectron2.**"
      ],
      "metadata": {
        "id": "rECwmm2_Id7p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wW8zetrJIVjn",
        "outputId": "eb388a8f-b5de-46ff-e62c-747d39ab4edc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-wcbj044s\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-wcbj044s\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit c69939aa85460e8135f40bce908a6cddaa73065f\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (11.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.8.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.5.0)\n",
            "Collecting yacs>=0.1.8 (from detectron2==0.6)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.1.0)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (4.66.6)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.17.1)\n",
            "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n",
            "Collecting omegaconf<2.4,>=2.1 (from detectron2==0.6)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting hydra-core>=1.1 (from detectron2==0.6)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting black (from detectron2==0.6)\n",
            "  Downloading black-24.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.26.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.2)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n",
            "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (8.1.7)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from black->detectron2==0.6)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.3.6)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.12.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.68.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (3.0.2)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading black-24.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp310-cp310-linux_x86_64.whl size=5974659 sha256=36527ae35b6a649f826117d7ae11c9b4a585ce5bc167d43a9bd0a6373f180c7f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vdc308cb/wheels/47/e5/15/94c80df2ba85500c5d76599cc307c0a7079d0e221bb6fc4375\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61396 sha256=2d24c8418cf0b7fc38e8be6e8a08558e053898c990d87e8457b4b08cf1d2f07e\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=dec2f5d4c0b741344912faaa07040edb37fd322700d4bea49cc1b90eb52f00d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built detectron2 fvcore antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, black, fvcore, detectron2\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 black-24.10.0 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 omegaconf-2.3.0 pathspec-0.12.1 portalocker-3.0.0 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "1edb7add6da247dfbdb68d3032e05b7f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pip install 'git+https://github.com/facebookresearch/detectron2.git'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. How do you perform inference with Detectron2 using an online image**"
      ],
      "metadata": {
        "id": "d4mW2qKDI-r_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests Pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If-L3NBEJpVa",
        "outputId": "83a24f3e-0a3c-4862-9910-f7bfaaa4c580"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import requests\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "\n",
        "# Step 1: Download an online image\n",
        "image_url = \"/content/person.jpeg\"  # Replace with the actual image URL\n",
        "response = requests.get(image_url)\n",
        "image = Image.open(BytesIO(response.content))\n",
        "\n",
        "# Convert image to numpy array\n",
        "image_np = np.asarray(image)\n",
        "\n",
        "# Step 2: Configure the Detectron2 model\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Adjust path as needed\n",
        "cfg.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Set threshold for prediction score\n",
        "cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "# Step 3: Perform inference\n",
        "outputs = predictor(image_np)\n",
        "\n",
        "# Step 4: Visualize results\n",
        "v = Visualizer(image_np[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
        "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "# Convert visualization to a PIL image and display it\n",
        "output_image = Image.fromarray(out.get_image()[:, :, ::-1])\n",
        "output_image.show()\n"
      ],
      "metadata": {
        "id": "qBtkqJ_aNg5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. How do you visualize evaluation metrics in Detectron2, such as training loss**"
      ],
      "metadata": {
        "id": "4ZNcsUWEK1Wx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorboard\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yk36GJorJOjO",
        "outputId": "900fc0ab-8105-4ade-8d87-125a231a7335"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.68.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.utils.logger import setup_logger\n",
        "from detectron2.engine import DefaultTrainer\n",
        "\n",
        "setup_logger()\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "d-OKDzNQL5wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Path to metrics.json\n",
        "metrics_file = \"./output/metrics.json\"\n",
        "\n",
        "# Load metrics\n",
        "with open(metrics_file, \"r\") as f:\n",
        "    metrics = [json.loads(line) for line in f]\n",
        "\n",
        "# Convert to DataFrame\n",
        "metrics_df = pd.DataFrame(metrics)\n",
        "\n",
        "# Plot training loss\n",
        "plt.figure(figsize=(10, 6))\n",
        "metrics_df.plot(x=\"iteration\", y=\"total_loss\", kind=\"line\", title=\"Training Loss\")\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Total Loss\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Plot other metrics if available\n",
        "if \"bbox/AP\" in metrics_df.columns:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    metrics_df.plot(x=\"iteration\", y=\"bbox/AP\", kind=\"line\", title=\"Bounding Box Average Precision (AP)\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"AP\")\n",
        "    plt.grid()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "WLtJMPecMNia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. How do you run inference with TFOD2 on an online image**"
      ],
      "metadata": {
        "id": "Lplc2STgMWtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# Step 1: Load the pre-trained model\n",
        "model_dir = \"path/to/saved_model\"  # Replace with the path to your saved model\n",
        "detection_model = tf.saved_model.load(model_dir)\n",
        "\n",
        "# Step 2: Define a function for inference\n",
        "def run_inference(model, image_np):\n",
        "    # Convert image to a tensor and add a batch dimension\n",
        "    input_tensor = tf.convert_to_tensor(image_np)\n",
        "    input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "    # Run the model\n",
        "    detections = model(input_tensor)\n",
        "\n",
        "    # Convert detections to numpy arrays\n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # Convert detection classes to integers\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    return detections\n",
        "\n",
        "# Step 3: Download and preprocess the online image\n",
        "image_url = \"https://example.com/path/to/your/image.jpg\"  # Replace with an actual image URL\n",
        "response = requests.get(image_url)\n",
        "image = Image.open(BytesIO(response.content))\n",
        "\n",
        "# Convert image to a numpy array\n",
        "image_np = np.array(image)\n",
        "\n",
        "# Step 4: Perform inference\n",
        "detections = run_inference(detection_model, image_np)\n",
        "\n",
        "# Step 5: Display the detections\n",
        "# Draw bounding boxes and labels on the image\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "def visualize_detections(image_np, detections, threshold=0.5):\n",
        "    fig, ax = plt.subplots(1, figsize=(12, 8))\n",
        "    ax.imshow(image_np)\n",
        "\n",
        "    for i in range(len(detections['detection_scores'])):\n",
        "        score = detections['detection_scores'][i]\n",
        "        if score >= threshold:\n",
        "            # Get bounding box\n",
        "            bbox = detections['detection_boxes'][i]\n",
        "            ymin, xmin, ymax, xmax = bbox\n",
        "\n",
        "            # Scale box to image size\n",
        "            im_height, im_width, _ = image_np.shape\n",
        "            (xmin, xmax, ymin, ymax) = (xmin * im_width, xmax * im_width, ymin * im_height, ymax * im_height)\n",
        "\n",
        "            # Draw rectangle\n",
        "            rect = Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, linewidth=2, edgecolor='r', facecolor='none')\n",
        "            ax.add_patch(rect)\n",
        "\n",
        "            # Draw label\n",
        "            class_id = detections['detection_classes'][i]\n",
        "            ax.text(xmin, ymin - 10, f\"Class {class_id}: {score:.2f}\", color='red', fontsize=12, backgroundcolor='white')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "visualize_detections(image_np, detections)\n"
      ],
      "metadata": {
        "id": "cO5F6gn1MfXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. How do you install TensorFlow Object Detection API in Jupyter Notebook**"
      ],
      "metadata": {
        "id": "7RB-yjAPMxg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vz0750WxMxJ5",
        "outputId": "8edbbb3d-21df-45dc-d412-00f3f37881a7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "git clone https://github.com/tensorflow/models.git"
      ],
      "metadata": {
        "id": "sNzT98wGNV88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] += f\":{os.getcwd()}:{os.getcwd()}/slim\"\n"
      ],
      "metadata": {
        "id": "q8RE5lGHNFUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install .\n"
      ],
      "metadata": {
        "id": "mHTV238FNIFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python object_detection/builders/model_builder_tf2_test.py"
      ],
      "metadata": {
        "id": "OJsy9sBTNKfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils"
      ],
      "metadata": {
        "id": "x35TG4CrNOAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. How can you load a pre-trained TensorFlow Object Detection model**"
      ],
      "metadata": {
        "id": "FNsa7nPeNl7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the model\n",
        "model_dir = \"path/to/saved_model\"\n",
        "detection_model = tf.saved_model.load(model_dir)\n",
        "\n",
        "# Load an image\n",
        "image_path = \"path/to/your/image.jpg\"\n",
        "image = Image.open(image_path)\n",
        "image_np = np.array(image)\n",
        "\n",
        "# Perform inference\n",
        "input_tensor = tf.convert_to_tensor(image_np)\n",
        "input_tensor = input_tensor[tf.newaxis, ...]\n",
        "detections = detection_model(input_tensor)\n",
        "\n",
        "# Visualize detections\n",
        "def visualize_detections(image_np, detections, threshold=0.5):\n",
        "    import matplotlib.patches as patches\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(image_np)\n",
        "    ax = plt.gca()\n",
        "\n",
        "    for i in range(int(detections['num_detections'][0])):\n",
        "        score = detections['detection_scores'][0][i]\n",
        "        if score > threshold:\n",
        "            bbox = detections['detection_boxes'][0][i].numpy()\n",
        "            ymin, xmin, ymax, xmax = bbox\n",
        "            im_height, im_width, _ = image_np.shape\n",
        "            (xmin, xmax, ymin, ymax) = (xmin * im_width, xmax * im_width, ymin * im_height, ymax * im_height)\n",
        "\n",
        "            # Draw bounding box\n",
        "            rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, linewidth=2, edgecolor='r', facecolor='none')\n",
        "            ax.add_patch(rect)\n",
        "\n",
        "            # Label the box\n",
        "            ax.text(xmin, ymin - 10, f\"Score: {score:.2f}\", color='red', fontsize=12, backgroundcolor='white')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "visualize_detections(image_np, detections)\n"
      ],
      "metadata": {
        "id": "tWqOJbDVNvaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** 7.How do you preprocess an image from the web for TFOD2 inference**"
      ],
      "metadata": {
        "id": "p7I_fDmxN4Qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# Step 1: Fetch the image from the web\n",
        "image_url = \"https://example.com/path/to/image.jpg\"  # Replace with an actual image URL\n",
        "response = requests.get(image_url)\n",
        "image = Image.open(BytesIO(response.content))\n",
        "\n",
        "# Step 2: Resize the image (if required)\n",
        "input_size = (320, 320)  # Replace with the input size of your model\n",
        "image_resized = image.resize(input_size)\n",
        "\n",
        "# Step 3: Convert to NumPy array\n",
        "image_np = np.array(image_resized)\n",
        "\n",
        "# Step 4: Add a batch dimension\n",
        "input_tensor = tf.convert_to_tensor(image_np)\n",
        "input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "# The input_tensor is now ready for inference\n",
        "print(f\"Preprocessed image shape: {input_tensor.shape}\")\n"
      ],
      "metadata": {
        "id": "9C5BSOd9OAsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. How do you visualize bounding boxes for detected objects in TFOD2 inference.**"
      ],
      "metadata": {
        "id": "Opt-8UPqORaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.utils import label_map_util\n"
      ],
      "metadata": {
        "id": "rQEwIteNOIF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume `detection_model` is your loaded TFOD2 model\n",
        "# `image_np` is the input image as a NumPy array\n",
        "\n",
        "# Add batch dimension\n",
        "input_tensor = tf.convert_to_tensor(image_np)[tf.newaxis, ...]\n",
        "\n",
        "# Run inference\n",
        "detections = detection_model(input_tensor)\n",
        "\n",
        "# Convert tensors to NumPy arrays\n",
        "detections = {key: value.numpy() for key, value in detections.items()}\n",
        "detections['num_detections'] = int(detections['num_detections'][0])\n",
        "detections['detection_classes'] = detections['detection_classes'][0].astype(np.int64)\n",
        "detections['detection_boxes'] = detections['detection_boxes'][0]\n",
        "detections['detection_scores'] = detections['detection_scores'][0]\n"
      ],
      "metadata": {
        "id": "81EwF10sOJ89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the label map file\n",
        "label_map_path = \"path/to/label_map.pbtxt\"\n",
        "\n",
        "# Load the label map\n",
        "category_index = label_map_util.create_category_index_from_labelmap(label_map_path, use_display_name=True)\n"
      ],
      "metadata": {
        "id": "KbvOQoQVOhNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the detections on the image\n",
        "image_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "    image_with_detections,\n",
        "    detections['detection_boxes'],\n",
        "    detections['detection_classes'],\n",
        "    detections['detection_scores'],\n",
        "    category_index,\n",
        "    use_normalized_coordinates=True,\n",
        "    max_boxes_to_draw=20,         # Maximum number of boxes to draw\n",
        "    min_score_thresh=0.5,         # Minimum confidence threshold\n",
        "    agnostic_mode=False\n",
        ")\n",
        "\n",
        "# Display the image with detections\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(image_with_detections)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GEWxb0zHOjLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. How do you define classes for custom training in TFOD2.**"
      ],
      "metadata": {
        "id": "iYmxaT4SOmss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_checkpoint: \"path/to/pretrained_model_checkpoint/model.ckpt\"\n",
        "num_classes: 2  # Change this to your number of classes\n",
        "train_input_path: \"path/to/train.record\"\n",
        "eval_input_path: \"path/to/eval.record\"\n",
        "label_map_path: \"path/to/label_map.pbtxt\"\n"
      ],
      "metadata": {
        "id": "5MBAZKLQOqxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python3 models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path=path/to/your/pipeline.config \\\n",
        "    --model_dir=path/to/save/model \\\n",
        "    --checkpoint_dir=path/to/save/model \\\n",
        "    --eval_timeout=0\n"
      ],
      "metadata": {
        "id": "rNWhjOD3O0fF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python3 models/research/object_detection/exporter_main_v2.py \\\n",
        "    --input_type image_tensor \\\n",
        "    --pipeline_config_path=path/to/your/pipeline.config \\\n",
        "    --trained_checkpoint_dir=path/to/save/model \\\n",
        "    --output_directory=path/to/exported_model\n"
      ],
      "metadata": {
        "id": "NSoQcFIsO4DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. How do you resize an image before detecting object1**"
      ],
      "metadata": {
        "id": "DX0QPdvuO7OT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from object_detection.utils import visualization_utils as vis_util\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "# Load the label map (class names)\n",
        "label_map_path = 'path/to/label_map.pbtxt'\n",
        "category_index = label_map_util.create_category_index_from_labelmap(label_map_path, use_display_name=True)\n",
        "\n",
        "# Visualize the detections on the image\n",
        "image_with_detections = image_np.copy()\n",
        "\n",
        "vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "    image_with_detections,\n",
        "    output_dict['detection_boxes'][0].numpy(),\n",
        "    output_dict['detection_classes'][0].numpy().astype(np.int64),\n",
        "    output_dict['detection_scores'][0].numpy(),\n",
        "    category_index,\n",
        "    use_normalized_coordinates=True,\n",
        "    max_boxes_to_draw=20,\n",
        "    min_score_thresh=0.5,\n",
        "    agnostic_mode=False\n",
        ")\n",
        "\n",
        "# Display the image with bounding boxes\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(image_with_detections)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RpKO83otO5Ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12.  How can you apply a color filter (e.g., red filter) to an image?**"
      ],
      "metadata": {
        "id": "YO-GOSq3PIdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "3dAFFrnAPG-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "3FyHO0VCPYKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the image to a NumPy array\n",
        "image_np = np.array(image)\n",
        "\n",
        "# Check the shape of the image\n",
        "print(\"Image shape:\", image_np.shape)  # (height, width, channels)\n"
      ],
      "metadata": {
        "id": "3ssut6IlPbvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the red filter by setting the green and blue channels to zero\n",
        "image_with_red_filter = image_np.copy()\n",
        "image_with_red_filter[:, :, 1] = 0  # Set green channel to 0\n",
        "image_with_red_filter[:, :, 2] = 0  # Set blue channel to 0\n"
      ],
      "metadata": {
        "id": "YbzIHs1MPdtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the NumPy array back to a PIL image\n",
        "filtered_image = Image.fromarray(image_with_red_filter)\n",
        "\n",
        "# Show the filtered image\n",
        "filtered_image.show()\n"
      ],
      "metadata": {
        "id": "TevhW_eKPfWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the filtered image\n",
        "filtered_image.save('path_to_save_filtered_image.jpg')  # Replace with your desired path\n"
      ],
      "metadata": {
        "id": "2m22BaRxPhfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PhjYQnoIPHSw"
      }
    }
  ]
}